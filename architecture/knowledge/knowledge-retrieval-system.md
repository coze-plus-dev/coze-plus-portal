# çŸ¥è¯†åº“æ£€ç´¢å·¥ç¨‹æŠ€æœ¯è¯¦è§£

## ğŸ“‹ æ¦‚è¿°

æ£€ç´¢å·¥ç¨‹æ˜¯çŸ¥è¯†åº“ç³»ç»Ÿçš„æ ¸å¿ƒèƒ½åŠ›ï¼Œè´Ÿè´£å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºç²¾å‡†çš„çŸ¥è¯†æ£€ç´¢ç»“æœã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¤šè·¯å¬å›ã€é‡æ’åºã€ç¼“å­˜ç­‰å…³é”®æŠ€æœ¯çš„å®ç°åŸç†å’Œä»£ç æ¶æ„ã€‚

## ğŸ—ï¸ æ£€ç´¢æ¶æ„è®¾è®¡

### æ£€ç´¢æµç¨‹æ¦‚è§ˆ

```mermaid
graph TD
    A[ç”¨æˆ·æŸ¥è¯¢] --> B[æŸ¥è¯¢é¢„å¤„ç†]
    B --> C[æŸ¥è¯¢é‡å†™]
    C --> D[å¤šè·¯å¹¶è¡Œå¬å›]
    D --> E[å‘é‡æ£€ç´¢]
    D --> F[å…¨æ–‡æ£€ç´¢]
    D --> G[ç»“æ„åŒ–æ£€ç´¢]
    E --> H[ç»“æœèåˆ]
    F --> H
    G --> H
    H --> I[é‡æ’åº]
    I --> J[ç»“æœåå¤„ç†]
    J --> K[è¿”å›ç»“æœ]
```

### æ ¸å¿ƒæŠ€æœ¯æ¡†æ¶

æœ¬é¡¹ç›®ä½¿ç”¨ **å­—èŠ‚è·³åŠ¨å¼€æºçš„ Eino æ¡†æ¶** æ„å»ºæ£€ç´¢é“¾ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸º AI åº”ç”¨è®¾è®¡çš„ç»„åˆå¼ç¼–ç¨‹æ¡†æ¶ã€‚

**Eino æ¡†æ¶ä¼˜åŠ¿**:
- **ç»„åˆå¼ç¼–ç¨‹**: é“¾å¼å’Œå¹¶è¡Œç»„åˆ
- **ç±»å‹å®‰å…¨**: å¼ºç±»å‹æ£€æŸ¥
- **é«˜æ€§èƒ½**: æ”¯æŒå¹¶å‘æ‰§è¡Œ
- **å¯è§‚æµ‹æ€§**: å†…ç½®é“¾è·¯è¿½è¸ª

## ğŸ”§ æ£€ç´¢é“¾å®ç°

### æ£€ç´¢é“¾æ„å»º

**ä½ç½®**: `backend/domain/knowledge/service/retrieve.go:55`

```go
func (k *knowledgeSVC) Retrieve(ctx context.Context, request *RetrieveRequest) (*RetrieveResponse, error) {
    // 1. æ„å»ºæ£€ç´¢ä¸Šä¸‹æ–‡
    retrieveContext, err := k.newRetrieveContext(ctx, request)
    if err != nil {
        return nil, err
    }
    
    // 2. æ„å»º Eino æ£€ç´¢é“¾
    chain := compose.NewChain[*RetrieveContext, []*knowledgeModel.RetrieveSlice]()
    
    // 3. å®šä¹‰å¤„ç†èŠ‚ç‚¹
    rewriteNode := compose.InvokableLambda(k.queryRewriteNode)           // æŸ¥è¯¢é‡å†™
    vectorRetrieveNode := compose.InvokableLambda(k.vectorRetrieveNode)  // å‘é‡æ£€ç´¢
    esRetrieveNode := compose.InvokableLambda(k.esRetrieveNode)         // ESæ£€ç´¢
    nl2SqlRetrieveNode := compose.InvokableLambda(k.nl2SqlRetrieveNode) // NL2SQLæ£€ç´¢
    passRequestContextNode := compose.InvokableLambda(k.passRequestContext) // ä¸Šä¸‹æ–‡ä¼ é€’
    reRankNode := compose.InvokableLambda(k.reRankNode)                 // é‡æ’åº
    packResult := compose.InvokableLambda(k.packResults)                // ç»“æœæ‰“åŒ…
    
    // 4. æ„å»ºå¹¶è¡Œå¬å›èŠ‚ç‚¹
    parallelNode := compose.NewParallel().
        AddLambda("vectorRetrieveNode", vectorRetrieveNode).
        AddLambda("esRetrieveNode", esRetrieveNode).
        AddLambda("nl2SqlRetrieveNode", nl2SqlRetrieveNode).
        AddLambda("passRequestContext", passRequestContextNode)
    
    // 5. ç»„è£…å®Œæ•´æ£€ç´¢é“¾
    r, err := chain.
        AppendLambda(rewriteNode).          // æŸ¥è¯¢é‡å†™
        AppendParallel(parallelNode).       // å¹¶è¡Œå¬å›
        AppendLambda(reRankNode).           // é‡æ’åº
        AppendLambda(packResult).           // ç»“æœæ‰“åŒ…
        Compile(ctx)
    
    if err != nil {
        return nil, errorx.New(errno.ErrKnowledgeBuildRetrieveChainFailCode, errorx.KV("msg", err.Error()))
    }
    
    // 6. æ‰§è¡Œæ£€ç´¢é“¾
    output, err := r.Invoke(ctx, retrieveContext)
    return &RetrieveResponse{Slices: output}, err
}
```

### æ£€ç´¢ä¸Šä¸‹æ–‡è®¾è®¡

```go
type RetrieveContext struct {
    // åŸå§‹æŸ¥è¯¢ä¿¡æ¯
    Query               string
    KnowledgeIDs        []int64
    TopK                int
    ScoreThreshold      float64
    
    // é‡å†™åçš„æŸ¥è¯¢
    RewrittenQueries    []string
    
    // æ£€ç´¢ç»“æœ
    VectorResults       []*VectorRetrieveResult
    ESResults          []*ESRetrieveResult
    NL2SQLResults      []*NL2SQLRetrieveResult
    
    // ä¸Šä¸‹æ–‡ä¿¡æ¯
    Documents          []*entity.Document
    SearchStoreMap     map[int64]searchstore.SearchStore
    
    // é…ç½®å‚æ•°
    EnableRewrite      bool
    EnableRerank       bool
    RerankTopK         int
}
```

## ğŸš€ å¤šè·¯å¬å›å®ç°

### 1. å‘é‡æ£€ç´¢

**æ ¸å¿ƒæ€æƒ³**: åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„å¯†é›†æ£€ç´¢

```go
func (k *knowledgeSVC) vectorRetrieveNode(ctx context.Context, retrieveCtx *RetrieveContext) (*RetrieveContext, error) {
    var allResults []*VectorRetrieveResult
    
    // å¯¹æ¯ä¸ªçŸ¥è¯†åº“å¹¶è¡Œæ£€ç´¢
    for knowledgeID, searchStore := range retrieveCtx.SearchStoreMap {
        // æ„å»ºæ£€ç´¢è¯·æ±‚
        retrieveRequest := &retriever.RetrieveRequest{
            Query:  retrieveCtx.Query,
            TopK:   retrieveCtx.TopK,
            Option: map[string]interface{}{
                "score_threshold": retrieveCtx.ScoreThreshold,
                "collection_name": getCollectionName(knowledgeID),
            },
        }
        
        // æ‰§è¡Œå‘é‡æ£€ç´¢
        retrieveResp, err := searchStore.Retrieve(ctx, retrieveRequest)
        if err != nil {
            logs.CtxErrorf(ctx, "vector retrieve failed: %v", err)
            continue
        }
        
        // è½¬æ¢æ£€ç´¢ç»“æœ
        for _, doc := range retrieveResp.Documents {
            result := &VectorRetrieveResult{
                SliceID:     extractSliceID(doc.ID),
                Score:       doc.Score,
                Content:     doc.Content,
                KnowledgeID: knowledgeID,
                Source:      "vector",
            }
            allResults = append(allResults, result)
        }
    }
    
    // æŒ‰åˆ†æ•°æ’åº
    sort.Slice(allResults, func(i, j int) bool {
        return allResults[i].Score > allResults[j].Score
    })
    
    retrieveCtx.VectorResults = allResults
    return retrieveCtx, nil
}
```

### 2. å…¨æ–‡æ£€ç´¢ (Elasticsearch)

**æ ¸å¿ƒæ€æƒ³**: åŸºäºå…³é”®è¯åŒ¹é…çš„ç¨€ç–æ£€ç´¢

```go
func (k *knowledgeSVC) esRetrieveNode(ctx context.Context, retrieveCtx *RetrieveContext) (*RetrieveContext, error) {
    var allResults []*ESRetrieveResult
    
    for knowledgeID, searchStore := range retrieveCtx.SearchStoreMap {
        // æ„å»ºESæŸ¥è¯¢
        query := buildESQuery(retrieveCtx.Query)
        
        retrieveRequest := &retriever.RetrieveRequest{
            Query:  query,
            TopK:   retrieveCtx.TopK,
            Option: map[string]interface{}{
                "index_name": getIndexName(knowledgeID),
                "highlight": map[string]interface{}{
                    "fields": map[string]interface{}{
                        "content": map[string]interface{}{},
                    },
                },
            },
        }
        
        // æ‰§è¡ŒESæ£€ç´¢
        retrieveResp, err := searchStore.Retrieve(ctx, retrieveRequest)
        if err != nil {
            logs.CtxErrorf(ctx, "es retrieve failed: %v", err)
            continue
        }
        
        // å¤„ç†æ£€ç´¢ç»“æœ
        for _, doc := range retrieveResp.Documents {
            result := &ESRetrieveResult{
                SliceID:     extractSliceID(doc.ID),
                Score:       doc.Score,
                Content:     doc.Content,
                Highlight:   extractHighlight(doc.Metadata),
                KnowledgeID: knowledgeID,
                Source:      "elasticsearch",
            }
            allResults = append(allResults, result)
        }
    }
    
    retrieveCtx.ESResults = allResults
    return retrieveCtx, nil
}

// æ„å»ºESæŸ¥è¯¢DSL
func buildESQuery(userQuery string) string {
    queryDSL := map[string]interface{}{
        "query": map[string]interface{}{
            "bool": map[string]interface{}{
                "should": []interface{}{
                    // ç²¾ç¡®åŒ¹é…
                    map[string]interface{}{
                        "match_phrase": map[string]interface{}{
                            "content": map[string]interface{}{
                                "query": userQuery,
                                "boost": 3.0,
                            },
                        },
                    },
                    // æ¨¡ç³ŠåŒ¹é…
                    map[string]interface{}{
                        "match": map[string]interface{}{
                            "content": map[string]interface{}{
                                "query":     userQuery,
                                "boost":     2.0,
                                "fuzziness": "AUTO",
                            },
                        },
                    },
                    // å¤šå­—æ®µåŒ¹é…
                    map[string]interface{}{
                        "multi_match": map[string]interface{}{
                            "query":  userQuery,
                            "fields": []string{"title^2", "content"},
                            "boost":  1.0,
                        },
                    },
                },
                "minimum_should_match": 1,
            },
        },
    }
    
    jsonBytes, _ := json.Marshal(queryDSL)
    return string(jsonBytes)
}
```

### 3. ç»“æ„åŒ–æ£€ç´¢ (NL2SQL)

**æ ¸å¿ƒæ€æƒ³**: è‡ªç„¶è¯­è¨€è½¬SQLæŸ¥è¯¢è¡¨æ ¼æ•°æ®

```go
func (k *knowledgeSVC) nl2SqlRetrieveNode(ctx context.Context, retrieveCtx *RetrieveContext) (*RetrieveContext, error) {
    var allResults []*NL2SQLRetrieveResult
    
    // åªå¯¹è¡¨æ ¼ç±»å‹æ–‡æ¡£æ‰§è¡ŒNL2SQLæ£€ç´¢
    tableDocuments := filterTableDocuments(retrieveCtx.Documents)
    if len(tableDocuments) == 0 {
        retrieveCtx.NL2SQLResults = allResults
        return retrieveCtx, nil
    }
    
    for _, doc := range tableDocuments {
        // æ„å»ºè¡¨ç»“æ„æè¿°
        schema := buildTableSchema(doc.TableInfo)
        
        // è°ƒç”¨NL2SQLæœåŠ¡
        nl2sqlRequest := &nl2sql.TranslateRequest{
            Query:        retrieveCtx.Query,
            TableSchema:  schema,
            DatabaseType: "mysql",
        }
        
        sqlResponse, err := k.nl2Sql.Translate(ctx, nl2sqlRequest)
        if err != nil {
            logs.CtxErrorf(ctx, "nl2sql translate failed: %v", err)
            continue
        }
        
        // æ‰§è¡ŒSQLæŸ¥è¯¢
        queryRequest := &rdb.QueryDataRequest{
            TableName: doc.TableInfo.PhysicalTableName,
            SQL:       sqlResponse.SQL,
            Limit:     retrieveCtx.TopK,
        }
        
        queryResponse, err := k.rdb.QueryData(ctx, queryRequest)
        if err != nil {
            logs.CtxErrorf(ctx, "sql query failed: %v", err)
            continue
        }
        
        // æ„å»ºç»“æœ
        for _, row := range queryResponse.Rows {
            result := &NL2SQLRetrieveResult{
                SliceID:     extractSliceIDFromRow(row),
                Content:     formatRowAsText(row, doc.TableInfo.Columns),
                SQL:         sqlResponse.SQL,
                KnowledgeID: doc.KnowledgeID,
                Source:      "nl2sql",
                Score:       1.0, // NL2SQLç»“æœå›ºå®šé«˜åˆ†
            }
            allResults = append(allResults, result)
        }
    }
    
    retrieveCtx.NL2SQLResults = allResults
    return retrieveCtx, nil
}

// æ„å»ºè¡¨ç»“æ„æè¿°
func buildTableSchema(tableInfo *entity.TableInfo) *nl2sql.TableSchema {
    columns := make([]*nl2sql.Column, 0, len(tableInfo.Columns))
    
    for _, col := range tableInfo.Columns {
        columns = append(columns, &nl2sql.Column{
            Name:        col.Name,
            Type:        convertColumnType(col.Type),
            Description: col.Description,
            IsPrimary:   col.Name == "id",
            IsNullable:  !col.Indexing,
        })
    }
    
    return &nl2sql.TableSchema{
        TableName:   tableInfo.VirtualTableName,
        Description: tableInfo.TableDesc,
        Columns:     columns,
    }
}
```

## ğŸ¯ æŸ¥è¯¢é‡å†™å®ç°

### æŸ¥è¯¢é‡å†™ç­–ç•¥

```go
func (k *knowledgeSVC) queryRewriteNode(ctx context.Context, retrieveCtx *RetrieveContext) (*RetrieveContext, error) {
    if !retrieveCtx.EnableRewrite || k.rewriter == nil {
        retrieveCtx.RewrittenQueries = []string{retrieveCtx.Query}
        return retrieveCtx, nil
    }
    
    // æ„å»ºé‡å†™è¯·æ±‚
    rewriteRequest := &messages2query.MessagesToQueryRequest{
        Messages: []*messages2query.Message{
            {
                Role:    "user",
                Content: retrieveCtx.Query,
            },
        },
        Context: buildRewriteContext(retrieveCtx),
    }
    
    // æ‰§è¡ŒæŸ¥è¯¢é‡å†™
    rewriteResponse, err := k.rewriter.Rewrite(ctx, rewriteRequest)
    if err != nil {
        logs.CtxErrorf(ctx, "query rewrite failed: %v", err)
        retrieveCtx.RewrittenQueries = []string{retrieveCtx.Query}
        return retrieveCtx, nil
    }
    
    // åˆå¹¶åŸæŸ¥è¯¢å’Œé‡å†™æŸ¥è¯¢
    queries := []string{retrieveCtx.Query}
    for _, query := range rewriteResponse.Queries {
        if query != retrieveCtx.Query {
            queries = append(queries, query)
        }
    }
    
    retrieveCtx.RewrittenQueries = queries
    return retrieveCtx, nil
}

// æ„å»ºé‡å†™ä¸Šä¸‹æ–‡
func buildRewriteContext(retrieveCtx *RetrieveContext) map[string]interface{} {
    return map[string]interface{}{
        "knowledge_domains": extractDomains(retrieveCtx.Documents),
        "document_types":    extractDocumentTypes(retrieveCtx.Documents),
        "table_schemas":     extractTableSchemas(retrieveCtx.Documents),
    }
}
```

## ğŸ”„ é‡æ’åºå®ç°

### é‡æ’åºç­–ç•¥

```go
func (k *knowledgeSVC) reRankNode(ctx context.Context, retrieveCtx *RetrieveContext) (*RetrieveContext, error) {
    if !retrieveCtx.EnableRerank {
        return retrieveCtx, nil
    }
    
    // 1. æ”¶é›†æ‰€æœ‰æ£€ç´¢ç»“æœ
    allResults := collectAllResults(retrieveCtx)
    if len(allResults) == 0 {
        return retrieveCtx, nil
    }
    
    // 2. RRF ç®—æ³•èåˆå¤šè·¯ç»“æœ
    rrfResults := k.applyRRF(allResults)
    
    // 3. è¯­ä¹‰é‡æ’åº
    if k.reranker != nil && len(rrfResults) > 1 {
        rerankResults, err := k.applySemanticRerank(ctx, retrieveCtx.Query, rrfResults)
        if err != nil {
            logs.CtxErrorf(ctx, "semantic rerank failed: %v", err)
        } else {
            rrfResults = rerankResults
        }
    }
    
    // 4. æ›´æ–°æ£€ç´¢ä¸Šä¸‹æ–‡
    retrieveCtx.FinalResults = rrfResults[:min(len(rrfResults), retrieveCtx.RerankTopK)]
    return retrieveCtx, nil
}

// RRF (Reciprocal Rank Fusion) ç®—æ³•å®ç°
func (k *knowledgeSVC) applyRRF(allResults []*RetrieveResult) []*RetrieveResult {
    const k = 60.0 // RRF å¸¸æ•°
    
    // æŒ‰æ¥æºåˆ†ç»„
    sourceGroups := make(map[string][]*RetrieveResult)
    for _, result := range allResults {
        sourceGroups[result.Source] = append(sourceGroups[result.Source], result)
    }
    
    // ä¸ºæ¯ä¸ªæ¥æºçš„ç»“æœæ’åº
    for source, results := range sourceGroups {
        sort.Slice(results, func(i, j int) bool {
            return results[i].Score > results[j].Score
        })
    }
    
    // è®¡ç®—RRFåˆ†æ•°
    rrfScores := make(map[string]float64)
    for source, results := range sourceGroups {
        for rank, result := range results {
            key := fmt.Sprintf("%d_%s", result.SliceID, result.Source)
            rrfScores[key] += 1.0 / (k + float64(rank+1))
        }
    }
    
    // å»é‡å¹¶æŒ‰RRFåˆ†æ•°æ’åº
    uniqueResults := make(map[int64]*RetrieveResult)
    for _, result := range allResults {
        key := fmt.Sprintf("%d_%s", result.SliceID, result.Source)
        if existing, exists := uniqueResults[result.SliceID]; !exists || rrfScores[key] > existing.RRFScore {
            result.RRFScore = rrfScores[key]
            uniqueResults[result.SliceID] = result
        }
    }
    
    // è½¬æ¢ä¸ºåˆ‡ç‰‡å¹¶æ’åº
    finalResults := make([]*RetrieveResult, 0, len(uniqueResults))
    for _, result := range uniqueResults {
        finalResults = append(finalResults, result)
    }
    
    sort.Slice(finalResults, func(i, j int) bool {
        return finalResults[i].RRFScore > finalResults[j].RRFScore
    })
    
    return finalResults
}

// è¯­ä¹‰é‡æ’åºå®ç°
func (k *knowledgeSVC) applySemanticRerank(ctx context.Context, query string, results []*RetrieveResult) ([]*RetrieveResult, error) {
    // æ„å»ºé‡æ’åºæ–‡æ¡£
    documents := make([]rerank.Document, 0, len(results))
    for i, result := range results {
        documents = append(documents, rerank.Document{
            ID:      strconv.Itoa(i),
            Content: result.Content,
        })
    }
    
    // æ‰§è¡Œé‡æ’åº
    rerankRequest := &rerank.RerankRequest{
        Query:     query,
        Documents: documents,
        TopK:      len(documents),
    }
    
    rerankResponse, err := k.reranker.Rerank(ctx, rerankRequest)
    if err != nil {
        return nil, err
    }
    
    // é‡æ–°æ’åºç»“æœ
    rerankedResults := make([]*RetrieveResult, 0, len(rerankResponse.Documents))
    for _, doc := range rerankResponse.Documents {
        index, _ := strconv.Atoi(doc.ID)
        if index < len(results) {
            result := results[index]
            result.RerankScore = doc.Score
            rerankedResults = append(rerankedResults, result)
        }
    }
    
    return rerankedResults, nil
}
```

## ğŸ’¾ ç¼“å­˜ç­–ç•¥å®ç°

### å¤šå±‚ç¼“å­˜æ¶æ„

```go
type CacheManager struct {
    // L1: å†…å­˜ç¼“å­˜ (è¿›ç¨‹å†…)
    memoryCache *sync.Map
    
    // L2: Redisç¼“å­˜ (åˆ†å¸ƒå¼)
    redisCache cache.Cmdable
    
    // ç¼“å­˜é…ç½®
    config CacheConfig
}

type CacheConfig struct {
    MemoryCacheSize    int           // å†…å­˜ç¼“å­˜å¤§å°
    MemoryExpire      time.Duration // å†…å­˜ç¼“å­˜è¿‡æœŸæ—¶é—´
    RedisExpire       time.Duration // Redisç¼“å­˜è¿‡æœŸæ—¶é—´
    EnableCompression bool          // æ˜¯å¦å¯ç”¨å‹ç¼©
}
```

### æ£€ç´¢ç»“æœç¼“å­˜

```go
func (k *knowledgeSVC) getCachedResults(ctx context.Context, cacheKey string) ([]*RetrieveResult, bool) {
    // L1: æ£€æŸ¥å†…å­˜ç¼“å­˜
    if value, ok := k.memoryCache.Load(cacheKey); ok {
        if cachedResults, ok := value.([]*RetrieveResult); ok {
            return cachedResults, true
        }
    }
    
    // L2: æ£€æŸ¥Redisç¼“å­˜
    cmd := k.redisCache.Get(ctx, cacheKey)
    if cmd.Err() == nil {
        var cachedResults []*RetrieveResult
        if err := json.Unmarshal([]byte(cmd.Val()), &cachedResults); err == nil {
            // å›å¡«å†…å­˜ç¼“å­˜
            k.memoryCache.Store(cacheKey, cachedResults)
            return cachedResults, true
        }
    }
    
    return nil, false
}

func (k *knowledgeSVC) setCachedResults(ctx context.Context, cacheKey string, results []*RetrieveResult) {
    // å­˜å‚¨åˆ°å†…å­˜ç¼“å­˜
    k.memoryCache.Store(cacheKey, results)
    
    // å­˜å‚¨åˆ°Redisç¼“å­˜
    if data, err := json.Marshal(results); err == nil {
        k.redisCache.Set(ctx, cacheKey, data, k.config.RedisExpire)
    }
}

// ç”Ÿæˆç¼“å­˜é”®
func generateCacheKey(request *RetrieveRequest) string {
    hasher := sha256.New()
    hasher.Write([]byte(request.Query))
    hasher.Write([]byte(fmt.Sprintf("%v", request.KnowledgeIDs)))
    hasher.Write([]byte(fmt.Sprintf("%d_%f", request.TopK, request.ScoreThreshold)))
    
    return fmt.Sprintf("retrieve:%x", hasher.Sum(nil))
}
```

### é¢„çƒ­ç­–ç•¥

```go
// çƒ­ç‚¹æŸ¥è¯¢é¢„çƒ­
func (k *knowledgeSVC) warmupCache(ctx context.Context) {
    // è·å–çƒ­ç‚¹æŸ¥è¯¢
    hotQueries := k.getHotQueries(ctx)
    
    // å¹¶å‘é¢„çƒ­
    var wg sync.WaitGroup
    semaphore := make(chan struct{}, 10) // é™åˆ¶å¹¶å‘æ•°
    
    for _, query := range hotQueries {
        wg.Add(1)
        go func(q string) {
            defer wg.Done()
            semaphore <- struct{}{}
            defer func() { <-semaphore }()
            
            // æ‰§è¡Œé¢„çƒ­æŸ¥è¯¢
            request := &RetrieveRequest{
                Query:        q,
                KnowledgeIDs: k.getAllKnowledgeIDs(ctx),
                TopK:         20,
            }
            
            _, _ = k.Retrieve(ctx, request)
        }(query)
    }
    
    wg.Wait()
}
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### æ€§èƒ½æŒ‡æ ‡æ”¶é›†

```go
type RetrieveMetrics struct {
    // å»¶è¿ŸæŒ‡æ ‡
    TotalLatency       time.Duration
    RewriteLatency     time.Duration
    VectorLatency      time.Duration
    ESLatency          time.Duration
    NL2SQLLatency      time.Duration
    RerankLatency      time.Duration
    
    // å¬å›æŒ‡æ ‡
    VectorRecallCount  int
    ESRecallCount      int
    NL2SQLRecallCount  int
    FinalResultCount   int
    
    // ç¼“å­˜æŒ‡æ ‡
    CacheHitRate       float64
    CacheQueryCount    int
    
    // é”™è¯¯æŒ‡æ ‡
    ErrorCount         int
    ErrorRate          float64
}

func (k *knowledgeSVC) recordMetrics(ctx context.Context, metrics *RetrieveMetrics) {
    // è®°å½•åˆ°Prometheus
    retrieveLatencyHistogram.Observe(metrics.TotalLatency.Seconds())
    cacheHitRateGauge.Set(metrics.CacheHitRate)
    
    // è®°å½•åˆ°æ—¥å¿—
    logs.CtxInfof(ctx, "retrieve metrics: %+v", metrics)
}
```

## ğŸš¨ æ•…éšœå¤„ç†

### é™çº§ç­–ç•¥

```go
func (k *knowledgeSVC) handleRetrieveFailure(ctx context.Context, retrieveCtx *RetrieveContext, err error) *RetrieveResponse {
    logs.CtxErrorf(ctx, "retrieve failed, applying fallback strategy: %v", err)
    
    // 1. å°è¯•ç¼“å­˜é™çº§
    if cachedResults := k.getCachedFallbackResults(ctx, retrieveCtx.Query); len(cachedResults) > 0 {
        return &RetrieveResponse{Slices: cachedResults}
    }
    
    // 2. ç®€åŒ–æ£€ç´¢ç­–ç•¥
    if simpleResults := k.simpleKeywordSearch(ctx, retrieveCtx); len(simpleResults) > 0 {
        return &RetrieveResponse{Slices: simpleResults}
    }
    
    // 3. è¿”å›ç©ºç»“æœ
    return &RetrieveResponse{Slices: []*knowledgeModel.RetrieveSlice{}}
}

// ç®€åŒ–å…³é”®è¯æœç´¢
func (k *knowledgeSVC) simpleKeywordSearch(ctx context.Context, retrieveCtx *RetrieveContext) []*knowledgeModel.RetrieveSlice {
    // ä½¿ç”¨æ•°æ®åº“LIKEæŸ¥è¯¢ä½œä¸ºæœ€åçš„é™çº§æ–¹æ¡ˆ
    keywords := extractKeywords(retrieveCtx.Query)
    
    var results []*knowledgeModel.RetrieveSlice
    for _, keyword := range keywords {
        slices, err := k.sliceRepo.SearchByKeyword(ctx, keyword, 10)
        if err == nil {
            for _, slice := range slices {
                results = append(results, convertSliceToRetrieveSlice(slice))
            }
        }
    }
    
    return results
}
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-10-27  
**ç›¸å…³æ–‡æ¡£**: [çŸ¥è¯†åº“æ¶æ„æ€»è§ˆ](./knowledge-base-architecture.md)