# æ¨¡åž‹é…ç½®æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•åœ¨ Coze Plus ä¸­é…ç½®å’Œç®¡ç†å¤§è¯­è¨€æ¨¡åž‹ï¼ŒåŒ…æ‹¬æ·»åŠ æ–°æ¨¡åž‹ã€é…ç½®å‚æ•°ã€ç®¡ç† API Key ç­‰æ“ä½œæŒ‡å—ã€‚

## å¿«é€Ÿå¼€å§‹

### 5 åˆ†é’Ÿé…ç½®ä¸€ä¸ª OpenAI æ¨¡åž‹

ä»¥é…ç½® GPT-4o æ¨¡åž‹ä¸ºä¾‹ï¼š

#### æ­¥éª¤ 1ï¼šèŽ·å– API Key

1. è®¿é—® [OpenAI Platform](https://platform.openai.com/)
2. ç™»å½•è´¦å·ï¼Œè¿›å…¥ API Keys é¡µé¢
3. ç‚¹å‡» "Create new secret key"
4. å¤åˆ¶ç”Ÿæˆçš„ API Keyï¼ˆæ ¼å¼ï¼š`sk-...`ï¼‰

#### æ­¥éª¤ 2ï¼šä¿®æ”¹æ¨¡åž‹é…ç½®æ–‡ä»¶

åœ¨ `backend/conf/model/template/` ç›®å½•æ‰¾åˆ° `model_template_openai.yaml`ï¼Œå¤åˆ¶å¹¶é‡å‘½åä¸º `model_gpt4o.yaml`ï¼š

```yaml
id: 69010
name: GPT-4o
icon_uri: default_icon/openai_v2.png
description:
  zh: GPT-4o å¤šæ¨¡æ€æ¨¡åž‹
  en: GPT-4o multi-modal model

meta:
  protocol: openai
  capability:
    function_call: true
    input_modal: [text, image]
    input_tokens: 128000
    output_tokens: 16384

  conn_config:
    base_url: "https://api.openai.com/v1"
    api_key: "sk-your-api-key-here"     # å¡«å…¥ä½ çš„ API Key
    model: "gpt-4o"                      # æ¨¡åž‹åç§°
    temperature: 0.7
    max_tokens: 4096
```

#### æ­¥éª¤ 3ï¼šé‡å¯æœåŠ¡

```bash
# é‡å¯ Coze Plus åŽç«¯æœåŠ¡
make server
```

#### æ­¥éª¤ 4ï¼šéªŒè¯é…ç½®

éªŒè¯æ–¹æ³•ï¼š
1. æ‰“å¼€ Coze Plus å‰ç«¯ç•Œé¢
2. åˆ›å»ºä¸€ä¸ªæ–°çš„æ™ºèƒ½ä½“
3. åœ¨æ¨¡åž‹é€‰æ‹©ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹©æ–°é…ç½®çš„ GPT-4o æ¨¡åž‹
4. å‘é€æµ‹è¯•æ¶ˆæ¯ï¼ŒéªŒè¯æ¨¡åž‹å“åº”æ˜¯å¦æ­£å¸¸

å®Œæˆï¼çŽ°åœ¨å¯ä»¥åœ¨æ™ºèƒ½ä½“ä¸­ä½¿ç”¨ GPT-4o æ¨¡åž‹äº†ã€‚

## é€šè¿‡ç®¡ç†ç•Œé¢é…ç½®æ¨¡åž‹

**æŽ¨èæ–¹å¼**ï¼šCoze Plus æä¾›äº†å¯è§†åŒ–çš„åŽå°ç®¡ç†ç•Œé¢æ¥é…ç½®æ¨¡åž‹ï¼Œæ— éœ€æ‰‹åŠ¨ç¼–è¾‘ YAML æ–‡ä»¶ï¼Œæ›´åŠ ç›´è§‚å’Œå®‰å…¨ã€‚

### ç•Œé¢é…ç½®ä¼˜åŠ¿

âœ… **å›¾å½¢åŒ–æ“ä½œ**ï¼šé€šè¿‡è¡¨å•ç•Œé¢å¡«å†™é…ç½®ï¼Œæ— éœ€äº†è§£ YAML è¯­æ³•
âœ… **å®žæ—¶éªŒè¯**ï¼šåˆ›å»ºæ¨¡åž‹æ—¶è‡ªåŠ¨æµ‹è¯•è¿žæŽ¥ï¼Œç¡®ä¿é…ç½®æ­£ç¡®
âœ… **å®‰å…¨åŠ å¯†**ï¼šAPI Key è‡ªåŠ¨åŠ å¯†å­˜å‚¨åœ¨æ•°æ®åº“ä¸­
âœ… **åŠ¨æ€ç®¡ç†**ï¼šæ— éœ€é‡å¯æœåŠ¡å³å¯æ·»åŠ ã€åˆ é™¤æ¨¡åž‹
âœ… **æƒé™æŽ§åˆ¶**ï¼šä»…ç®¡ç†å‘˜å¯è®¿é—®æ¨¡åž‹é…ç½®é¡µé¢

### 5 åˆ†é’Ÿé€šè¿‡ç•Œé¢æ·»åŠ æ¨¡åž‹

ä»¥æ·»åŠ  GPT-4o æ¨¡åž‹ä¸ºä¾‹ï¼š

#### æ­¥éª¤ 1ï¼šè®¿é—®ç®¡ç†åŽå°

1. ç™»å½• Coze Plus
2. ç‚¹å‡»å³ä¸Šè§’å¤´åƒï¼Œé€‰æ‹© **"ç®¡ç†åŽå°"** æˆ– **"ç³»ç»Ÿè®¾ç½®"**
3. åœ¨å·¦ä¾§èœå•ä¸­é€‰æ‹© **"æ¨¡åž‹ç®¡ç†"** > **"LLM æ¨¡åž‹"**

#### æ­¥éª¤ 2ï¼šåˆ›å»ºæ–°æ¨¡åž‹

ç‚¹å‡»é¡µé¢å³ä¸Šè§’çš„ **"æ·»åŠ æ¨¡åž‹"** æŒ‰é’®ï¼Œè¿›å…¥åˆ›å»ºè¡¨å•ã€‚

#### æ­¥éª¤ 3ï¼šé€‰æ‹©æ¨¡åž‹æä¾›å•†

åœ¨ **"æä¾›å•†"** ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹© **"OpenAI"**ã€‚ç³»ç»Ÿä¼šæ˜¾ç¤ºè¯¥æä¾›å•†æ”¯æŒçš„æ‰€æœ‰æ¨¡åž‹ã€‚

#### æ­¥éª¤ 4ï¼šå¡«å†™æ¨¡åž‹ä¿¡æ¯

**åŸºæœ¬ä¿¡æ¯**ï¼š
- **æ¨¡åž‹åç§°**ï¼šGPT-4oï¼ˆè‡ªå®šä¹‰æ˜¾ç¤ºåç§°ï¼‰
- **æ¨¡åž‹ç±»åž‹**ï¼šLLMï¼ˆå¤§è¯­è¨€æ¨¡åž‹ï¼‰

**è¿žæŽ¥é…ç½®**ï¼š
- **API ç«¯ç‚¹** (Base URL)ï¼š`https://api.openai.com/v1`
- **API Key**ï¼š`sk-your-openai-api-key-here`
- **æ¨¡åž‹åç§°** (Model)ï¼š`gpt-4o`

**å¯é€‰é…ç½®**ï¼š
- **Temperature**ï¼š0.7
- **Max Tokens**ï¼š4096
- **Top P**ï¼š1.0

**é«˜çº§é€‰é¡¹**ï¼ˆæ ¹æ®éœ€è¦å¡«å†™ï¼‰ï¼š
- **ä½¿ç”¨ Azure OpenAI**ï¼šå¦ï¼ˆé»˜è®¤ï¼‰
- **å¯ç”¨ Base64 URL æ”¯æŒ**ï¼šå¦ï¼ˆé»˜è®¤ï¼‰

#### æ­¥éª¤ 5ï¼šæµ‹è¯•è¿žæŽ¥

ç‚¹å‡» **"æµ‹è¯•è¿žæŽ¥"** æŒ‰é’®ï¼Œç³»ç»Ÿä¼šï¼š
1. ä½¿ç”¨å¡«å†™çš„é…ç½®æž„å»ºæ¨¡åž‹å®¢æˆ·ç«¯
2. å‘é€æµ‹è¯•æ¶ˆæ¯ï¼š"1+1=?, Just answer with a number"
3. éªŒè¯æ¨¡åž‹æ˜¯å¦æ­£å¸¸å“åº”

**æµ‹è¯•æˆåŠŸ**ï¼š
```
âœ“ æ¨¡åž‹è¿žæŽ¥æˆåŠŸ
å“åº”æ—¶é—´: 1.2s
æµ‹è¯•å“åº”: 2
```

**æµ‹è¯•å¤±è´¥ç¤ºä¾‹**ï¼š
```
âœ— æ¨¡åž‹è¿žæŽ¥å¤±è´¥
é”™è¯¯ä¿¡æ¯: Incorrect API key provided
è¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®
```

#### æ­¥éª¤ 6ï¼šä¿å­˜é…ç½®

æµ‹è¯•é€šè¿‡åŽï¼Œç‚¹å‡» **"ä¿å­˜"** æŒ‰é’®ã€‚ç³»ç»Ÿä¼šï¼š
1. åŠ å¯† API Keyï¼ˆä½¿ç”¨ AES-256ï¼‰
2. å°†é…ç½®ä¿å­˜åˆ°æ•°æ®åº“ `model_instance` è¡¨
3. ç«‹å³ç”Ÿæ•ˆï¼Œæ— éœ€é‡å¯æœåŠ¡

**ä¿å­˜æˆåŠŸæç¤º**ï¼š
```
âœ“ æ¨¡åž‹åˆ›å»ºæˆåŠŸ
æ¨¡åž‹ ID: 10001
çŽ°åœ¨å¯ä»¥åœ¨æ™ºèƒ½ä½“ä¸­ä½¿ç”¨ GPT-4o äº†
```

#### æ­¥éª¤ 7ï¼šéªŒè¯æ¨¡åž‹

1. è¿”å›ž **"æ¨¡åž‹ç®¡ç†"** åˆ—è¡¨é¡µ
2. åœ¨ **"OpenAI"** åˆ†ç»„ä¸‹æ‰¾åˆ°æ–°åˆ›å»ºçš„ **"GPT-4o"**
3. çŠ¶æ€æ˜¾ç¤ºä¸º **"ä½¿ç”¨ä¸­"** âœ“
4. åˆ›å»ºæ™ºèƒ½ä½“æ—¶å¯åœ¨æ¨¡åž‹ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹©è¯¥æ¨¡åž‹

### ç®¡ç†ç•Œé¢åŠŸèƒ½

#### æŸ¥çœ‹æ¨¡åž‹åˆ—è¡¨

**API æŽ¥å£**ï¼š
```bash
GET /api/admin/config/model/list
```

**è¯·æ±‚ç¤ºä¾‹**ï¼š
```bash
curl -X GET http://localhost:8888/api/admin/config/model/list \
  -H "Authorization: Bearer admin-token" \
  -H "Content-Type: application/json"
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "code": 0,
  "msg": "success",
  "provider_model_list": [
    {
      "provider": {
        "name": {
          "zh_cn": "OpenAI",
          "en_us": "OpenAI"
        },
        "icon_uri": "default_icon/openai_v2.png",
        "model_class": "GPT"
      },
      "model_list": [
        {
          "id": 10001,
          "display_info": {
            "name": "GPT-4o",
            "output_tokens": 16384,
            "max_tokens": 128000
          },
          "capability": {
            "function_call": true,
            "input_modal": ["text", "image"],
            "input_tokens": 128000,
            "output_tokens": 16384
          },
          "status": 1,
          "enable_base64_url": false
        }
      ]
    }
  ]
}
```

ç•Œé¢ä¼šå°†æ¨¡åž‹æŒ‰æä¾›å•†åˆ†ç»„å±•ç¤ºï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â—‹ GPT-4o                    [ç¼–è¾‘] [åˆ é™¤]â”‚
â”‚   è¾“å…¥: 128K tokens | è¾“å‡º: 16K tokens   â”‚
â”‚   æ”¯æŒ: å‡½æ•°è°ƒç”¨, å¤šæ¨¡æ€(æ–‡æœ¬+å›¾åƒ)       â”‚
â”‚   çŠ¶æ€: âœ“ ä½¿ç”¨ä¸­                         â”‚
â”‚                                         â”‚
â”‚ â—‹ GPT-4o-mini              [ç¼–è¾‘] [åˆ é™¤]â”‚
â”‚   è¾“å…¥: 128K tokens | è¾“å‡º: 16K tokens   â”‚
â”‚   çŠ¶æ€: âœ“ ä½¿ç”¨ä¸­                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Claude                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â—‹ Claude-3.5-Sonnet        [ç¼–è¾‘] [åˆ é™¤]â”‚
â”‚   è¾“å…¥: 200K tokens | è¾“å‡º: 8K tokens    â”‚
â”‚   æ”¯æŒ: å‰ç¼€ç¼“å­˜, é¢„å¡«å……å“åº”              â”‚
â”‚   çŠ¶æ€: âœ“ ä½¿ç”¨ä¸­                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### åˆ›å»ºæ¨¡åž‹

**API æŽ¥å£**ï¼š
```bash
POST /api/admin/config/model/create
```

**è¯·æ±‚å‚æ•°**ï¼š

| å­—æ®µ | ç±»åž‹ | å¿…å¡« | è¯´æ˜Ž |
|------|------|------|------|
| `model_class` | string | æ˜¯ | æ¨¡åž‹ç±»åž‹ï¼š`GPT`/`Claude`/`Gemini`/`DeepSeek`/`Qwen`/`Ollama`/`Ark` |
| `model_name` | string | æ˜¯ | æ¨¡åž‹æ˜¾ç¤ºåç§° |
| `connection` | object | æ˜¯ | è¿žæŽ¥é…ç½®å¯¹è±¡ |
| `connection.base_conn_info` | object | æ˜¯ | åŸºç¡€è¿žæŽ¥ä¿¡æ¯ |
| `connection.base_conn_info.base_url` | string | æ˜¯ | API ç«¯ç‚¹ URL |
| `connection.base_conn_info.api_key` | string | æ˜¯ | API å¯†é’¥ |
| `connection.base_conn_info.model` | string | æ˜¯ | æ¨¡åž‹åç§°ï¼ˆå¦‚ `gpt-4o`ï¼‰ |
| `connection.openai` | object | å¦ | OpenAI ç‰¹å®šé…ç½® |
| `connection.openai.by_azure` | boolean | å¦ | æ˜¯å¦ä½¿ç”¨ Azure OpenAI |
| `connection.openai.api_version` | string | å¦ | API ç‰ˆæœ¬ï¼ˆAzure éœ€è¦ï¼‰ |
| `enable_base64_url` | boolean | å¦ | æ˜¯å¦å¯ç”¨ Base64 URL æ”¯æŒ |

**è¯·æ±‚ç¤ºä¾‹**ï¼š
```bash
curl -X POST http://localhost:8888/api/admin/config/model/create \
  -H "Authorization: Bearer admin-token" \
  -H "Content-Type: application/json" \
  -d '{
    "model_class": "GPT",
    "model_name": "GPT-4o",
    "connection": {
      "base_conn_info": {
        "base_url": "https://api.openai.com/v1",
        "api_key": "sk-your-api-key-here",
        "model": "gpt-4o"
      },
      "openai": {
        "by_azure": false,
        "request_dims": 0
      }
    },
    "enable_base64_url": false
  }'
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "code": 0,
  "msg": "success",
  "id": "10001"
}
```

**åˆ›å»ºæµç¨‹è¯´æ˜Ž**ï¼š

1. **å‚æ•°éªŒè¯**ï¼šæ£€æŸ¥å¿…å¡«å­—æ®µã€URL æ ¼å¼ã€API Key æ ¼å¼
2. **æ¨¡åž‹æž„å»º**ï¼šæ ¹æ® `model_class` åˆ›å»ºå¯¹åº”çš„æ¨¡åž‹ Builder
3. **è¿žæŽ¥æµ‹è¯•**ï¼šå‘é€æµ‹è¯•æ¶ˆæ¯éªŒè¯æ¨¡åž‹å¯ç”¨æ€§
   ```go
   // æµ‹è¯•æ¶ˆæ¯
   testMessage := "1+1=?, Just answer with a number, no explanation."
   ```
4. **åŠ å¯†å­˜å‚¨**ï¼šä½¿ç”¨ AES-256 åŠ å¯† API Key
5. **æŒä¹…åŒ–**ï¼šä¿å­˜åˆ° `model_instance` è¡¨å¹¶è¿”å›žæ¨¡åž‹ ID

**æºç ä½ç½®**ï¼š`backend/api/handler/coze/config_service.go:170`

#### åˆ é™¤æ¨¡åž‹

**API æŽ¥å£**ï¼š
```bash
POST /api/admin/config/model/delete
```

**è¯·æ±‚ç¤ºä¾‹**ï¼š
```bash
curl -X POST http://localhost:8888/api/admin/config/model/delete \
  -H "Authorization: Bearer admin-token" \
  -H "Content-Type: application/json" \
  -d '{
    "id": "10001"
  }'
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "code": 0,
  "msg": "success"
}
```

**åˆ é™¤è§„åˆ™**ï¼š
- æ¨¡åž‹çŠ¶æ€æ›´æ–°ä¸º `StatusDeleted` (2)
- ä¸ä¼šç‰©ç†åˆ é™¤è®°å½•ï¼Œä»…è½¯åˆ é™¤
- åˆ é™¤åŽåœ¨æ™ºèƒ½ä½“ä¸­ä¸å†å¯é€‰
- å·²ä½¿ç”¨è¯¥æ¨¡åž‹çš„æ™ºèƒ½ä½“ä¸å—å½±å“ï¼ˆåŽ†å²è®°å½•ä¿ç•™ï¼‰

**æºç ä½ç½®**ï¼š`backend/api/handler/coze/config_service.go:221`

### ä¸åŒæä¾›å•†é…ç½®ç¤ºä¾‹

#### OpenAI / Azure OpenAI

**æ ‡å‡† OpenAI**ï¼š
```json
{
  "model_class": "GPT",
  "model_name": "GPT-4o",
  "connection": {
    "base_conn_info": {
      "base_url": "https://api.openai.com/v1",
      "api_key": "sk-...",
      "model": "gpt-4o"
    },
    "openai": {
      "by_azure": false
    }
  }
}
```

**Azure OpenAI**ï¼š
```json
{
  "model_class": "GPT",
  "model_name": "GPT-4o (Azure)",
  "connection": {
    "base_conn_info": {
      "base_url": "https://your-resource.openai.azure.com",
      "api_key": "azure-api-key",
      "model": "gpt-4o-deployment-name"
    },
    "openai": {
      "by_azure": true,
      "api_version": "2024-02-01"
    }
  }
}
```

#### Claude (Anthropic)

```json
{
  "model_class": "Claude",
  "model_name": "Claude-3.5-Sonnet",
  "connection": {
    "base_conn_info": {
      "base_url": "https://api.anthropic.com/v1/",
      "api_key": "sk-ant-...",
      "model": "claude-3-5-sonnet-20241022"
    },
    "claude": {}
  }
}
```

#### Google Gemini

```json
{
  "model_class": "Gemini",
  "model_name": "Gemini-1.5-Pro",
  "connection": {
    "base_conn_info": {
      "base_url": "https://generativelanguage.googleapis.com/v1",
      "api_key": "your-google-api-key",
      "model": "gemini-1.5-pro"
    },
    "gemini": {
      "backend": 1
    }
  }
}
```

#### DeepSeek

```json
{
  "model_class": "DeepSeek",
  "model_name": "DeepSeek-V3",
  "connection": {
    "base_conn_info": {
      "base_url": "https://api.deepseek.com/v1",
      "api_key": "sk-...",
      "model": "deepseek-chat"
    },
    "deepseek": {}
  }
}
```

#### Alibaba Qwen

```json
{
  "model_class": "Qwen",
  "model_name": "Qwen-Max",
  "connection": {
    "base_conn_info": {
      "base_url": "https://dashscope.aliyuncs.com/api/v1",
      "api_key": "sk-...",
      "model": "qwen-max"
    },
    "qwen": {}
  }
}
```

#### Ollama (æœ¬åœ°)

```json
{
  "model_class": "Ollama",
  "model_name": "Llama-3.3-70B",
  "connection": {
    "base_conn_info": {
      "base_url": "http://host.docker.internal:11434",
      "api_key": "",
      "model": "llama3.3:70b"
    },
    "ollama": {}
  }
}
```

#### ByteDance Ark

```json
{
  "model_class": "Ark",
  "model_name": "Doubao-1.5-Pro",
  "connection": {
    "base_conn_info": {
      "base_url": "https://ark.cn-beijing.volces.com/api/v3",
      "api_key": "your-ark-api-key",
      "model": "doubao-pro-128k"
    },
    "ark": {
      "region": "cn-beijing",
      "api_type": ""
    }
  }
}
```

### ç•Œé¢é…ç½® vs æ–‡ä»¶é…ç½®

| å¯¹æ¯”ç»´åº¦ | ç•Œé¢é…ç½® | æ–‡ä»¶é…ç½® |
|----------|----------|----------|
| **æ“ä½œéš¾åº¦** | â­â­â­â­â­ å›¾å½¢åŒ–è¡¨å• | â­â­â­ éœ€è¦äº†è§£ YAML è¯­æ³• |
| **å®žæ—¶éªŒè¯** | âœ… åˆ›å»ºæ—¶è‡ªåŠ¨æµ‹è¯•è¿žæŽ¥ | âŒ éœ€æ‰‹åŠ¨æµ‹è¯• |
| **å®‰å…¨æ€§** | âœ… API Key è‡ªåŠ¨åŠ å¯† | âš ï¸ æ˜Žæ–‡å­˜å‚¨æˆ–éœ€æ‰‹åŠ¨ç®¡ç† |
| **ç”Ÿæ•ˆé€Ÿåº¦** | âœ… ç«‹å³ç”Ÿæ•ˆï¼Œæ— éœ€é‡å¯ | âŒ éœ€é‡å¯æœåŠ¡ |
| **é€‚ç”¨åœºæ™¯** | ç”Ÿäº§çŽ¯å¢ƒã€è¿ç»´ç®¡ç† | å¼€å‘çŽ¯å¢ƒã€æ‰¹é‡é…ç½® |
| **ç‰ˆæœ¬æŽ§åˆ¶** | âŒ å­˜å‚¨åœ¨æ•°æ®åº“ | âœ… å¯æäº¤åˆ° Git |
| **æ‰¹é‡æ“ä½œ** | âš ï¸ éœ€é€ä¸ªåˆ›å»º | âœ… æ”¯æŒè„šæœ¬æ‰¹é‡ç”Ÿæˆ |
| **æƒé™æŽ§åˆ¶** | âœ… ä»…ç®¡ç†å‘˜å¯è®¿é—® | âš ï¸ ä¾èµ–æ–‡ä»¶ç³»ç»Ÿæƒé™ |

**æŽ¨èä½¿ç”¨åœºæ™¯**ï¼š

âœ… **ä½¿ç”¨ç•Œé¢é…ç½®**ï¼š
- ç”Ÿäº§çŽ¯å¢ƒæ·»åŠ æ–°æ¨¡åž‹
- è¿ç»´äººå‘˜æ—¥å¸¸ç®¡ç†
- éœ€è¦å¿«é€ŸéªŒè¯é…ç½®
- æ•æ„Ÿä¿¡æ¯å®‰å…¨è¦æ±‚é«˜

âœ… **ä½¿ç”¨æ–‡ä»¶é…ç½®**ï¼š
- å¼€å‘çŽ¯å¢ƒå¿«é€Ÿæµ‹è¯•
- æ‰¹é‡é…ç½®å¤šä¸ªæ¨¡åž‹
- CI/CD è‡ªåŠ¨åŒ–éƒ¨ç½²
- éœ€è¦ç‰ˆæœ¬æŽ§åˆ¶é…ç½®

### å¸¸è§é—®é¢˜

#### Q1: ç•Œé¢åˆ›å»ºçš„æ¨¡åž‹åœ¨å“ªé‡Œå­˜å‚¨ï¼Ÿ

**ç­”**ï¼šå­˜å‚¨åœ¨æ•°æ®åº“ `model_instance` è¡¨ä¸­ï¼Œç»“æž„å¦‚ä¸‹ï¼š

```sql
CREATE TABLE `model_instance` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `provider` varchar(50) NOT NULL,
  `model_class` varchar(50) NOT NULL,
  `display_info` json NOT NULL,
  `capability` json NOT NULL,
  `connection` json NOT NULL,        -- API Key å·²åŠ å¯†
  `type` int NOT NULL DEFAULT '0',
  `parameters` json DEFAULT NULL,
  `status` int NOT NULL DEFAULT '1',
  `enable_base64_url` tinyint(1) DEFAULT '0',
  `created_at` bigint NOT NULL,
  `updated_at` bigint NOT NULL,
  `delete_at_ms` bigint DEFAULT '0',
  PRIMARY KEY (`id`)
);
```

**æŸ¥è¯¢ç¤ºä¾‹**ï¼š
```sql
-- æŸ¥çœ‹æ‰€æœ‰æ¨¡åž‹ï¼ˆä¸æ˜¾ç¤ºåŠ å¯†çš„ API Keyï¼‰
SELECT id, provider, model_class,
       JSON_EXTRACT(display_info, '$.name') AS name,
       status
FROM model_instance
WHERE status != 2;  -- 2 = StatusDeleted
```

**æºç ä½ç½®**ï¼š`backend/bizpkg/config/modelmgr/modelmgr.go:38`

#### Q2: å¦‚ä½•åœ¨ç•Œé¢å’Œæ–‡ä»¶é…ç½®ä¹‹é—´åˆ‡æ¢ï¼Ÿ

**ç­”**ï¼šä¸¤ç§é…ç½®æ–¹å¼å¯ä»¥å…±å­˜ï¼š
- **æ–‡ä»¶é…ç½®** çš„æ¨¡åž‹ä»Ž YAML æ–‡ä»¶åŠ è½½åˆ°å†…å­˜
- **ç•Œé¢é…ç½®** çš„æ¨¡åž‹ä»Žæ•°æ®åº“åŠ è½½
- ç³»ç»Ÿå¯åŠ¨æ—¶ä¼šåˆå¹¶ä¸¤è€…ï¼ŒæŒ‰ ID åŽ»é‡ï¼ˆæ•°æ®åº“ä¼˜å…ˆï¼‰

**åŠ è½½é¡ºåº**ï¼š
1. åŠ è½½ `backend/conf/model/template/*.yaml` æ–‡ä»¶
2. åŠ è½½æ•°æ®åº“ `model_instance` è¡¨
3. åˆå¹¶æ¨¡åž‹åˆ—è¡¨ï¼ˆID å†²çªæ—¶æ•°æ®åº“é…ç½®è¦†ç›–æ–‡ä»¶é…ç½®ï¼‰

**ID è§„åˆ’å»ºè®®**ï¼š
- æ–‡ä»¶é…ç½®ï¼šä½¿ç”¨ 60000-69999 èŒƒå›´
- ç•Œé¢é…ç½®ï¼šä½¿ç”¨ 10000-59999 èŒƒå›´ï¼ˆç³»ç»Ÿè‡ªåŠ¨åˆ†é…ï¼‰

#### Q3: API Key å¦‚ä½•åŠ å¯†å­˜å‚¨ï¼Ÿ

**ç­”**ï¼šä½¿ç”¨ AES-256-CBC åŠ å¯†ç®—æ³•ï¼š

1. **åŠ å¯†æµç¨‹**ï¼š
   ```go
   // ç”Ÿæˆå¯†é’¥ï¼ˆä»ŽçŽ¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ï¼‰
   key := []byte("your-32-byte-encryption-key-here")

   // åŠ å¯† API Key
   encryptedKey := aes.Encrypt(apiKey, key)

   // å­˜å‚¨åˆ°æ•°æ®åº“
   connection := {"api_key": encryptedKey}
   ```

2. **è§£å¯†æµç¨‹**ï¼š
   ```go
   // ä»Žæ•°æ®åº“è¯»å–
   connection := loadFromDB()

   // è§£å¯† API Key
   apiKey := aes.Decrypt(connection.APIKey, key)

   // ä½¿ç”¨æ˜Žæ–‡ API Key è°ƒç”¨æ¨¡åž‹
   ```

**å®‰å…¨å»ºè®®**ï¼š
- åŠ å¯†å¯†é’¥å­˜å‚¨åœ¨çŽ¯å¢ƒå˜é‡ `MODEL_ENCRYPTION_KEY` ä¸­
- å®šæœŸè½®æ¢åŠ å¯†å¯†é’¥
- æ•°æ®åº“å¤‡ä»½æ—¶ç¡®ä¿åŠ å¯†å¯†é’¥åŒæ­¥å¤‡ä»½

**æºç ä½ç½®**ï¼š`backend/bizpkg/config/modelmgr/model_meta.go`

#### Q4: æµ‹è¯•è¿žæŽ¥å¤±è´¥æ€Žä¹ˆåŠžï¼Ÿ

**å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ**ï¼š

| é”™è¯¯ä¿¡æ¯ | åŽŸå›  | è§£å†³æ–¹æ¡ˆ |
|----------|------|----------|
| `Incorrect API key provided` | API Key æ— æ•ˆ | æ£€æŸ¥ API Key æ ¼å¼å’Œæœ‰æ•ˆæœŸ |
| `Connection timeout` | ç½‘ç»œè¶…æ—¶ | æ£€æŸ¥ç½‘ç»œè¿žæŽ¥å’Œ base_url |
| `Model not found` | æ¨¡åž‹åç§°é”™è¯¯ | ç¡®è®¤ model å­—æ®µä¸Žæä¾›å•†æ–‡æ¡£ä¸€è‡´ |
| `Rate limit exceeded` | API è°ƒç”¨é¢‘çŽ‡è¶…é™ | ç¨åŽé‡è¯•æˆ–å‡çº§å¥—é¤ |
| `Invalid base_url` | URL æ ¼å¼é”™è¯¯ | ç¡®ä¿ URL åŒ…å«åè®®ï¼ˆhttp/httpsï¼‰ |

**è°ƒè¯•æ­¥éª¤**ï¼š
1. åœ¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·ä¸­æŸ¥çœ‹ç½‘ç»œè¯·æ±‚
2. æ£€æŸ¥åŽç«¯æ—¥å¿—ï¼š`tail -f logs/coze-plus.log | grep "model"`
3. ä½¿ç”¨ curl ç›´æŽ¥æµ‹è¯• APIï¼š
   ```bash
   curl https://api.openai.com/v1/chat/completions \
     -H "Authorization: Bearer sk-..." \
     -H "Content-Type: application/json" \
     -d '{"model":"gpt-4o","messages":[{"role":"user","content":"test"}]}'
   ```

#### Q5: å¦‚ä½•è¿ç§»æ–‡ä»¶é…ç½®åˆ°ç•Œé¢ï¼Ÿ

**è¿ç§»æ­¥éª¤**ï¼š

1. **å¯¼å‡ºçŽ°æœ‰é…ç½®**ï¼š
   ```bash
   # åˆ—å‡ºæ‰€æœ‰ YAML é…ç½®
   ls backend/conf/model/template/*.yaml
   ```

2. **é€ä¸ªè¿ç§»**ï¼š
   - æ‰“å¼€ç®¡ç†ç•Œé¢
   - ç‚¹å‡» "æ·»åŠ æ¨¡åž‹"
   - æŒ‰ç…§ YAML é…ç½®å¡«å†™è¡¨å•
   - æµ‹è¯•è¿žæŽ¥å¹¶ä¿å­˜

3. **éªŒè¯è¿ç§»**ï¼š
   ```bash
   # æ£€æŸ¥æ•°æ®åº“
   mysql -u root -p coze_plus -e \
     "SELECT id, JSON_EXTRACT(display_info, '$.name') AS name FROM model_instance;"
   ```

4. **æ¸…ç†æ–‡ä»¶é…ç½®**ï¼ˆå¯é€‰ï¼‰ï¼š
   ```bash
   # å¤‡ä»½åŽŸæ–‡ä»¶
   mkdir -p backup/model_configs
   cp backend/conf/model/template/*.yaml backup/model_configs/

   # åˆ é™¤å·²è¿ç§»çš„æ–‡ä»¶
   rm backend/conf/model/template/model_gpt4o.yaml
   ```

**æ‰¹é‡è¿ç§»è„šæœ¬**ï¼ˆå‚è€ƒï¼‰ï¼š
```bash
#!/bin/bash
# migrate_models.sh

API_BASE="http://localhost:8888/api/admin/config/model"
TOKEN="admin-token"

for yaml_file in backend/conf/model/template/*.yaml; do
  echo "Migrating $yaml_file..."

  # è§£æž YAML å¹¶è½¬æ¢ä¸º JSONï¼ˆéœ€è¦ yq å·¥å…·ï¼‰
  json_data=$(yq eval -o=json "$yaml_file")

  # è°ƒç”¨åˆ›å»º API
  curl -X POST "$API_BASE/create" \
    -H "Authorization: Bearer $TOKEN" \
    -H "Content-Type: application/json" \
    -d "$json_data"

  echo "âœ“ Migrated $yaml_file"
done
```

## é…ç½®æ–‡ä»¶è¯¦è§£

### åŸºæœ¬ä¿¡æ¯

```yaml
id: 69010                          # æ¨¡åž‹ IDï¼Œå¿…é¡»å”¯ä¸€
name: GPT-4o                       # æ˜¾ç¤ºåç§°
icon_uri: default_icon/openai_v2.png  # å›¾æ ‡è·¯å¾„
icon_url: ""                       # å¤–éƒ¨å›¾æ ‡ URLï¼ˆå¯é€‰ï¼‰

description:                       # æ¨¡åž‹æè¿°ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰
  zh: GPT-4o æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€æ¨¡åž‹ï¼Œæ”¯æŒæ–‡æœ¬å’Œå›¾åƒè¾“å…¥
  en: GPT-4o is a multi-modal model supporting text and image inputs
```

### æ¨¡åž‹å‚æ•°

```yaml
default_parameters:
  - name: temperature              # å‚æ•°åç§°
    label:                         # æ˜¾ç¤ºæ ‡ç­¾
      zh: ç”Ÿæˆéšæœºæ€§
      en: Temperature
    desc:                          # å‚æ•°è¯´æ˜Ž
      zh: æŽ§åˆ¶è¾“å‡ºçš„å¤šæ ·æ€§å’Œåˆ›é€ æ€§
      en: Controls output diversity and creativity
    type: float                    # å‚æ•°ç±»åž‹ï¼šfloat | int | string
    min: "0"                       # æœ€å°å€¼
    max: "1"                       # æœ€å¤§å€¼
    default_val:                   # é»˜è®¤å€¼ï¼ˆæ”¯æŒé¢„è®¾ï¼‰
      balance: "0.8"               # å¹³è¡¡æ¨¡å¼
      creative: "1"                # åˆ›é€ æ¨¡å¼
      default_val: "1.0"           # é»˜è®¤å€¼
      precise: "0.3"               # ç²¾ç¡®æ¨¡å¼
    precision: 1                   # å°æ•°ç²¾åº¦
    options: []                    # é€‰é¡¹åˆ—è¡¨ï¼ˆç”¨äºŽæžšä¸¾ç±»åž‹ï¼‰
    style:                         # å‰ç«¯UIæ ·å¼
      widget: slider               # ç»„ä»¶ç±»åž‹ï¼šslider | input | radio_buttons
      label:                       # ç»„ä»¶åˆ†ç»„æ ‡ç­¾
        zh: ç”Ÿæˆå¤šæ ·æ€§
        en: Generation diversity
```

### æ¨¡åž‹èƒ½åŠ›

```yaml
meta:
  protocol: openai                 # åè®®ç±»åž‹
  capability:
    function_call: true            # æ˜¯å¦æ”¯æŒå‡½æ•°è°ƒç”¨
    input_modal:                   # è¾“å…¥æ¨¡æ€
      - text                       # æ”¯æŒæ–‡æœ¬
      - image                      # æ”¯æŒå›¾åƒ
    input_tokens: 128000           # è¾“å…¥ Token ä¸Šé™
    json_mode: false               # æ˜¯å¦æ”¯æŒ JSON æ¨¡å¼
    max_tokens: 128000             # æ€» Token ä¸Šé™
    output_modal:                  # è¾“å‡ºæ¨¡æ€
      - text
    output_tokens: 16384           # è¾“å‡º Token ä¸Šé™
    prefix_caching: false          # æ˜¯å¦æ”¯æŒå‰ç¼€ç¼“å­˜
    reasoning: false               # æ˜¯å¦æ”¯æŒæŽ¨ç†æ¨¡å¼
    prefill_response: false        # æ˜¯å¦æ”¯æŒé¢„å¡«å……å“åº”
```

### è¿žæŽ¥é…ç½®

```yaml
meta:
  conn_config:
    base_url: "https://api.openai.com/v1"  # API ç«¯ç‚¹
    api_key: ""                    # API å¯†é’¥ï¼ˆæ•æ„Ÿä¿¡æ¯ï¼‰
    timeout: 0s                    # è¶…æ—¶æ—¶é—´ï¼ˆ0 è¡¨ç¤ºä½¿ç”¨é»˜è®¤ï¼‰
    model: ""                      # æ¨¡åž‹åç§°ï¼ˆå¦‚ gpt-4oï¼‰
    temperature: 0.7               # é»˜è®¤æ¸©åº¦
    frequency_penalty: 0           # é¢‘çŽ‡æƒ©ç½š
    presence_penalty: 0            # å­˜åœ¨æƒ©ç½š
    max_tokens: 4096               # æœ€å¤§è¾“å‡º Token
    top_p: 1                       # Top P é‡‡æ ·
    top_k: 0                       # Top K é‡‡æ ·
    stop: []                       # åœæ­¢è¯åˆ—è¡¨

    # OpenAI ç‰¹å®šé…ç½®
    openai:
      by_azure: false              # æ˜¯å¦ä½¿ç”¨ Azure OpenAI
      api_version: ""              # API ç‰ˆæœ¬ï¼ˆAzure éœ€è¦ï¼‰
      response_format:             # å“åº”æ ¼å¼
        type: text                 # text | json_object
        jsonschema: null           # JSON Schemaï¼ˆå¯é€‰ï¼‰

    custom: {}                     # è‡ªå®šä¹‰é…ç½®
  status: 0                        # çŠ¶æ€ï¼š0-æ­£å¸¸ 1-ç¦ç”¨
```

## é…ç½®ä¸åŒæä¾›å•†

### OpenAI / Azure OpenAI

#### æ ‡å‡† OpenAI

```yaml
id: 69010
name: GPT-4o
meta:
  protocol: openai
  conn_config:
    base_url: "https://api.openai.com/v1"
    api_key: "sk-..."
    model: "gpt-4o"
    openai:
      by_azure: false
```

#### Azure OpenAI

```yaml
id: 69020
name: GPT-4o (Azure)
meta:
  protocol: openai
  conn_config:
    base_url: "https://your-resource.openai.azure.com"
    api_key: "azure-api-key"
    model: "gpt-4o-deployment-name"
    openai:
      by_azure: true
      api_version: "2024-02-01"
```

### Claude (Anthropic)

#### æ ‡å‡† Claude API

```yaml
id: 65010
name: Claude-3.5-Sonnet
meta:
  protocol: claude
  capability:
    function_call: true
    input_modal: [text, image]
    input_tokens: 200000
    output_tokens: 8192
    prefix_caching: true           # Claude æ”¯æŒå‰ç¼€ç¼“å­˜
    prefill_response: true         # Claude æ”¯æŒé¢„å¡«å……
  conn_config:
    base_url: "https://api.anthropic.com/v1/"
    api_key: "sk-ant-..."
    model: "claude-3-5-sonnet-20241022"
    claude:
      by_bedrock: false
```

#### AWS Bedrock Claude

```yaml
id: 65020
name: Claude-3.5-Sonnet (Bedrock)
meta:
  protocol: claude
  conn_config:
    base_url: ""
    api_key: ""
    model: "anthropic.claude-3-5-sonnet-20241022-v2:0"
    claude:
      by_bedrock: true
      access_key: "AWS_ACCESS_KEY_ID"
      secret_access_key: "AWS_SECRET_ACCESS_KEY"
      session_token: ""            # å¯é€‰
      region: "us-west-2"
```

### Google Gemini

```yaml
id: 67010
name: Gemini-Pro
meta:
  protocol: gemini
  capability:
    function_call: true
    input_modal: [text, image, audio, video]
    input_tokens: 1000000          # 1M ä¸Šä¸‹æ–‡
    output_tokens: 8192
  conn_config:
    base_url: "https://generativelanguage.googleapis.com/v1"
    api_key: "your-google-api-key"
    model: "gemini-1.5-pro"
    temperature: 0.7
```

### DeepSeek

#### DeepSeek V3

```yaml
id: 62010
name: DeepSeek-V3
meta:
  protocol: deepseek
  capability:
    function_call: true
    input_modal: [text]
    input_tokens: 64000
    output_tokens: 8192
  conn_config:
    base_url: "https://api.deepseek.com/v1"
    api_key: "sk-..."
    model: "deepseek-chat"
```

#### DeepSeek-R1 (æŽ¨ç†æ¨¡å¼)

```yaml
id: 62020
name: DeepSeek-R1
meta:
  protocol: deepseek
  capability:
    function_call: false
    input_modal: [text]
    input_tokens: 64000
    output_tokens: 8192
    reasoning: true                # æ”¯æŒ Chain-of-Thought æŽ¨ç†
  conn_config:
    base_url: "https://api.deepseek.com/v1"
    api_key: "sk-..."
    model: "deepseek-reasoner"
```

### Alibaba Qwen (é€šä¹‰åƒé—®)

```yaml
id: 64010
name: Qwen-Max
meta:
  protocol: qwen
  capability:
    function_call: true
    input_modal: [text]
    input_tokens: 32000
    output_tokens: 8192
  conn_config:
    base_url: "https://dashscope.aliyuncs.com/api/v1"
    api_key: "sk-..."
    model: "qwen-max"
```

### Ollama (æœ¬åœ°éƒ¨ç½²)

```yaml
id: 68010
name: Llama-3.3-70B
meta:
  protocol: ollama
  capability:
    function_call: true
    input_modal: [text]
    input_tokens: 128000
    output_tokens: 4096
  conn_config:
    base_url: "http://host.docker.internal:11434"  # Docker çŽ¯å¢ƒ
    # base_url: "http://localhost:11434"           # æœ¬åœ°çŽ¯å¢ƒ
    api_key: ""                    # Ollama ä¸éœ€è¦ API Key
    model: "llama3.3:70b"
    temperature: 0.6
    top_k: 20
```

**æ³¨æ„äº‹é¡¹**ï¼š
- Docker çŽ¯å¢ƒä½¿ç”¨ `host.docker.internal` è®¿é—®å®¿ä¸»æœº
- æœ¬åœ°çŽ¯å¢ƒä½¿ç”¨ `localhost` æˆ– `127.0.0.1`
- ç¡®ä¿ Ollama æœåŠ¡å·²å¯åŠ¨ï¼š`ollama serve`

### ByteDance Ark (å­—èŠ‚è±†åŒ…)

```yaml
id: 60010
name: Doubao-1.5-Pro
meta:
  protocol: ark
  capability:
    function_call: true
    input_modal: [text, image]
    input_tokens: 128000
    output_tokens: 8192
  conn_config:
    base_url: "https://ark.cn-beijing.volces.com/api/v3"
    api_key: "your-ark-api-key"
    model: "doubao-pro-128k"
```

## å‚æ•°UIç»„ä»¶

Coze Plus æ”¯æŒå¤šç§å‰ç«¯UIç»„ä»¶æ¥å±•ç¤ºå’Œè°ƒæ•´æ¨¡åž‹å‚æ•°ï¼š

### 1. Sliderï¼ˆæ»‘å—ï¼‰

é€‚ç”¨äºŽè¿žç»­æ•°å€¼å‚æ•°ï¼Œå¦‚ temperatureã€top_p ç­‰ï¼š

```yaml
- name: temperature
  type: float
  min: "0"
  max: "1"
  default_val:
    default_val: "0.7"
  precision: 1
  style:
    widget: slider
    label:
      zh: ç”Ÿæˆå¤šæ ·æ€§
      en: Generation diversity
```

**å‰ç«¯æ•ˆæžœ**ï¼š
```
ç”Ÿæˆå¤šæ ·æ€§
Temperature [0.7]
|----â—-----|
0         1
```

### 2. Inputï¼ˆè¾“å…¥æ¡†ï¼‰

é€‚ç”¨äºŽæ•´æ•°å‚æ•°ï¼Œå¦‚ max_tokensï¼š

```yaml
- name: max_tokens
  type: int
  min: "1"
  max: "4096"
  default_val:
    default_val: "4096"
  style:
    widget: input
```

**å‰ç«¯æ•ˆæžœ**ï¼š
```
Max Tokens
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4096   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Radio Buttonsï¼ˆå•é€‰æŒ‰é’®ï¼‰

é€‚ç”¨äºŽæžšä¸¾ç±»åž‹å‚æ•°ï¼Œå¦‚ response_formatï¼š

```yaml
- name: response_format
  type: int
  default_val:
    default_val: "0"
  options:
    - label: Text
      value: "0"
    - label: Markdown
      value: "1"
    - label: JSON
      value: "2"
  style:
    widget: radio_buttons
```

**å‰ç«¯æ•ˆæžœ**ï¼š
```
Response Format
â—‹ Text   â— Markdown   â—‹ JSON
```

### 4. Selectï¼ˆä¸‹æ‹‰é€‰æ‹©ï¼‰

é€‚ç”¨äºŽè¾ƒå¤šé€‰é¡¹çš„æžšä¸¾ï¼š

```yaml
- name: model_variant
  type: string
  default_val:
    default_val: "standard"
  options:
    - label: Standard
      value: "standard"
    - label: Turbo
      value: "turbo"
    - label: Premium
      value: "premium"
  style:
    widget: select
```

## ç®¡ç† API Key

### çŽ¯å¢ƒå˜é‡æ–¹å¼ï¼ˆæŽ¨èï¼‰

åœ¨ `.env` æ–‡ä»¶æˆ–ç³»ç»ŸçŽ¯å¢ƒå˜é‡ä¸­é…ç½®ï¼š

```bash
# .env
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=...
DEEPSEEK_API_KEY=sk-...
QWEN_API_KEY=sk-...
```

åœ¨é…ç½®æ–‡ä»¶ä¸­å¼•ç”¨ï¼š

```yaml
conn_config:
  api_key: "${OPENAI_API_KEY}"  # å¼•ç”¨çŽ¯å¢ƒå˜é‡
```

**ä¼˜ç‚¹**ï¼š
- æ•æ„Ÿä¿¡æ¯ä¸æäº¤åˆ°ä»£ç ä»“åº“
- ä¾¿äºŽä¸åŒçŽ¯å¢ƒåˆ‡æ¢
- ç¬¦åˆå®‰å…¨æœ€ä½³å®žè·µ

### é…ç½®æ–‡ä»¶æ–¹å¼

ç›´æŽ¥åœ¨ YAML æ–‡ä»¶ä¸­å¡«å†™ï¼ˆä»…å¼€å‘æµ‹è¯•ä½¿ç”¨ï¼‰ï¼š

```yaml
conn_config:
  api_key: "sk-..."
```

**æ³¨æ„**ï¼š
- âš ï¸ ä¸è¦å°†åŒ…å«çœŸå®ž API Key çš„é…ç½®æ–‡ä»¶æäº¤åˆ° Git
- âš ï¸ ç”Ÿäº§çŽ¯å¢ƒå¿…é¡»ä½¿ç”¨çŽ¯å¢ƒå˜é‡

### æ•°æ®åº“åŠ å¯†å­˜å‚¨

é€šè¿‡ç®¡ç†ç•Œé¢åˆ›å»ºçš„æ¨¡åž‹å®žä¾‹ï¼ŒAPI Key ä¼šè‡ªåŠ¨åŠ å¯†å­˜å‚¨åœ¨æ•°æ®åº“ä¸­ï¼š

```sql
SELECT id, provider, display_info
FROM model_instance
WHERE id = 1;

-- connection å­—æ®µä¸­çš„ api_key å·²åŠ å¯†
-- {"api_key": "AESåŠ å¯†åŽçš„å¯†æ–‡"}
```

## æµ‹è¯•æ¨¡åž‹é…ç½®

### æ–¹æ³• 1ï¼šå‘½ä»¤è¡Œæµ‹è¯•

```bash
# è¿›å…¥åŽç«¯ç›®å½•
cd backend

# è¿è¡Œæµ‹è¯•å‘½ä»¤
go run cmd/test/model_test.go \
  --model-id=69010 \
  --prompt="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"
```

### æ–¹æ³• 2ï¼šAPI æµ‹è¯•

```bash
curl -X POST http://localhost:8888/api/conversation/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-access-token" \
  -d '{
    "bot_id": "your-bot-id",
    "user_id": "test-user",
    "additional_messages": [
      {
        "role": "user",
        "content": "ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡åž‹ï¼Ÿ",
        "content_type": "text"
      }
    ],
    "stream": false
  }'
```

### æ–¹æ³• 3ï¼šå‰ç«¯æµ‹è¯•

1. æ‰“å¼€ Coze Plus å‰ç«¯ç•Œé¢
2. åˆ›å»ºä¸€ä¸ªæ–°çš„æ™ºèƒ½ä½“
3. åœ¨æ¨¡åž‹é€‰æ‹©ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹©æ–°é…ç½®çš„æ¨¡åž‹
4. å‘é€æµ‹è¯•æ¶ˆæ¯
5. éªŒè¯å“åº”æ˜¯å¦æ­£å¸¸

## å¸¸è§é—®é¢˜

### Q1: æ¨¡åž‹é…ç½®åŽä¸æ˜¾ç¤ºæ€Žä¹ˆåŠžï¼Ÿ

**å¯èƒ½åŽŸå› **ï¼š
1. é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯
2. ID é‡å¤
3. æœåŠ¡æœªé‡å¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# 1. éªŒè¯ YAML æ ¼å¼
yamllint model_gpt4o.yaml

# 2. æ£€æŸ¥ ID å”¯ä¸€æ€§
grep -r "^id: 69010" backend/conf/model/template/

# 3. é‡å¯æœåŠ¡
make server

# 4. æŸ¥çœ‹æ—¥å¿—
tail -f logs/coze-plus.log | grep "model"
```

### Q2: API Key æ— æ•ˆé”™è¯¯

**é”™è¯¯ä¿¡æ¯**ï¼š
```
Error: Incorrect API key provided
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ç¡®è®¤ API Key æ ¼å¼æ­£ç¡®
2. æ£€æŸ¥ API Key æ˜¯å¦è¿‡æœŸ
3. éªŒè¯ API Key æƒé™
4. ç¡®è®¤ base_url æ­£ç¡®

### Q3: æ¨¡åž‹å“åº”è¶…æ—¶

**é”™è¯¯ä¿¡æ¯**ï¼š
```
Error: Request timeout after 60s
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

è°ƒæ•´è¶…æ—¶é…ç½®ï¼š
```yaml
conn_config:
  timeout: 120s  # å»¶é•¿åˆ° 120 ç§’
```

æˆ–åœ¨ä»£ç ä¸­è®¾ç½®ï¼š
```go
client := &http.Client{
    Timeout: 120 * time.Second,
}
```

### Q4: æœ¬åœ° Ollama è¿žæŽ¥å¤±è´¥

**é”™è¯¯ä¿¡æ¯**ï¼š
```
Error: dial tcp 127.0.0.1:11434: connect: connection refused
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€ï¼š
```bash
# æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
ps aux | grep ollama

# å¯åŠ¨ Ollama æœåŠ¡
ollama serve
```

2. Docker çŽ¯å¢ƒä¿®æ”¹ URLï¼š
```yaml
conn_config:
  base_url: "http://host.docker.internal:11434"
```

3. æ‹‰å–æ¨¡åž‹ï¼š
```bash
ollama pull llama3.3:70b
```

### Q5: Token è¶…é™é”™è¯¯

**é”™è¯¯ä¿¡æ¯**ï¼š
```
Error: This model's maximum context length is 8192 tokens
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. å‡å°‘è¾“å…¥å†…å®¹é•¿åº¦
2. è°ƒæ•´ max_tokensï¼š
```yaml
conn_config:
  max_tokens: 2000  # å‡å°è¾“å‡ºé•¿åº¦
```
3. åˆ‡æ¢åˆ°æ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡çš„æ¨¡åž‹

### Q6: å¤šæ¨¡æ€è¾“å…¥ä¸ç”Ÿæ•ˆ

**é—®é¢˜**ï¼šå‘é€å›¾ç‰‡åŽæ¨¡åž‹æ— æ³•è¯†åˆ«

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. ç¡®è®¤æ¨¡åž‹æ”¯æŒå¤šæ¨¡æ€ï¼š
```yaml
capability:
  input_modal: [text, image]  # å¿…é¡»åŒ…å« image
```

2. å¯ç”¨ Base64 URL æ”¯æŒï¼ˆéƒ¨åˆ†æ¨¡åž‹éœ€è¦ï¼‰ï¼š
```yaml
meta:
  enable_base64_url: true
```

3. ç¡®è®¤å›¾ç‰‡æ ¼å¼å’Œå¤§å°ç¬¦åˆé™åˆ¶

## é«˜çº§é…ç½®

### è‡ªå®šä¹‰ HTTP Headers

æŸäº›æ¨¡åž‹æä¾›å•†éœ€è¦é¢å¤–çš„ HTTP Headersï¼š

```yaml
conn_config:
  custom:
    headers:
      X-Custom-Header: "value"
      User-Agent: "CozeP lus/1.0"
```

### ä»£ç†é…ç½®

é€šè¿‡ä»£ç†è®¿é—®æ¨¡åž‹ APIï¼š

```bash
# è®¾ç½®çŽ¯å¢ƒå˜é‡
export HTTP_PROXY=http://proxy.example.com:8080
export HTTPS_PROXY=http://proxy.example.com:8080
export NO_PROXY=localhost,127.0.0.1
```

æˆ–åœ¨é…ç½®ä¸­æŒ‡å®šï¼š

```yaml
conn_config:
  custom:
    proxy: "http://proxy.example.com:8080"
```

### é‡è¯•ç­–ç•¥

é…ç½®è¯·æ±‚å¤±è´¥é‡è¯•ï¼š

```yaml
conn_config:
  custom:
    retry:
      max_attempts: 3
      initial_interval: 1s
      max_interval: 10s
      multiplier: 2
```

### æ—¥å¿—çº§åˆ«

è°ƒæ•´æ¨¡åž‹è°ƒç”¨æ—¥å¿—çº§åˆ«ï¼š

```yaml
conn_config:
  custom:
    log_level: "debug"  # debug | info | warn | error
```

## æ‰¹é‡é…ç½®

å¦‚æžœéœ€è¦é…ç½®å¤šä¸ªåŒç±»åž‹æ¨¡åž‹ï¼Œå¯ä»¥ä½¿ç”¨è„šæœ¬æ‰¹é‡ç”Ÿæˆï¼š

```bash
#!/bin/bash
# generate_models.sh

MODELS=("gpt-4o" "gpt-4o-mini" "gpt-4-turbo")
BASE_ID=69000

for i in "${!MODELS[@]}"; do
  MODEL_NAME="${MODELS[$i]}"
  MODEL_ID=$((BASE_ID + i + 10))

  cat > "model_${MODEL_NAME}.yaml" << EOF
id: ${MODEL_ID}
name: ${MODEL_NAME}
icon_uri: default_icon/openai_v2.png
description:
  zh: ${MODEL_NAME} æ¨¡åž‹
  en: ${MODEL_NAME} model

meta:
  protocol: openai
  conn_config:
    base_url: "https://api.openai.com/v1"
    api_key: "\${OPENAI_API_KEY}"
    model: "${MODEL_NAME}"
    temperature: 0.7
    max_tokens: 4096
EOF

  echo "Generated model_${MODEL_NAME}.yaml"
done
```

è¿è¡Œè„šæœ¬ï¼š

```bash
chmod +x generate_models.sh
./generate_models.sh
```

## æœ€ä½³å®žè·µ

### DOï¼ˆæŽ¨èåšæ³•ï¼‰

âœ… **ä½¿ç”¨çŽ¯å¢ƒå˜é‡ç®¡ç†æ•æ„Ÿä¿¡æ¯**
```yaml
api_key: "${OPENAI_API_KEY}"
```

âœ… **ä¸ºä¸åŒçŽ¯å¢ƒä½¿ç”¨ä¸åŒé…ç½®**
```
- model_gpt4o_dev.yaml    # å¼€å‘çŽ¯å¢ƒ
- model_gpt4o_prod.yaml   # ç”Ÿäº§çŽ¯å¢ƒ
```

âœ… **é…ç½®åˆç†çš„è¶…æ—¶æ—¶é—´**
```yaml
conn_config:
  timeout: 60s  # æ ¹æ®å®žé™…ç½‘ç»œæƒ…å†µè°ƒæ•´
```

âœ… **å¯ç”¨è¯¦ç»†æ—¥å¿—ä¾¿äºŽæŽ’æŸ¥é—®é¢˜**
```yaml
conn_config:
  custom:
    log_level: "debug"
```

âœ… **å®šæœŸæ›´æ–°æ¨¡åž‹é…ç½®**
```bash
# æ£€æŸ¥æ–°ç‰ˆæœ¬
curl https://api.openai.com/v1/models

# æ›´æ–°é…ç½®
vim model_gpt4o.yaml
```

### DON'Tï¼ˆé¿å…åšæ³•ï¼‰

âŒ **ç¡¬ç¼–ç  API Key**
```yaml
# ä¸è¦è¿™æ ·
api_key: "sk-1234567890abcdef"
```

âŒ **å¿½ç•¥æ¨¡åž‹èƒ½åŠ›å£°æ˜Ž**
```yaml
# ä¸è¦å¿˜è®°é…ç½®
capability:
  function_call: true  # å¦‚æžœä¸æ”¯æŒï¼Œè®¾ä¸º false
```

âŒ **ä½¿ç”¨é”™è¯¯çš„ model åç§°**
```yaml
# ä¸è¦è¿™æ ·
model: "gpt4"  # é”™è¯¯ï¼Œåº”è¯¥æ˜¯ "gpt-4o"
```

âŒ **å¿½ç•¥ Token é™åˆ¶**
```yaml
# ä¸è¦è¶…è¿‡å®žé™…é™åˆ¶
max_tokens: 999999  # ä¼šå¯¼è‡´é”™è¯¯
```

âŒ **æ··ç”¨ä¸åŒåè®®çš„é…ç½®**
```yaml
# ä¸è¦è¿™æ ·ï¼ˆclaude æ¨¡åž‹ä½¿ç”¨ openai åè®®ï¼‰
protocol: openai
model: "claude-3-5-sonnet"  # é”™è¯¯
```

## å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [OpenAI API Docs](https://platform.openai.com/docs)
- [Anthropic Claude Docs](https://docs.anthropic.com/)
- [Google Gemini Docs](https://ai.google.dev/docs)
- [DeepSeek API Docs](https://platform.deepseek.com/docs)
- [Qwen API Docs](https://help.aliyun.com/zh/dashscope/)
- [Ollama Docs](https://github.com/ollama/ollama/blob/main/docs/api.md)

### ç›¸å…³æ–‡æ¡£

- [æ¨¡åž‹æŠ€æœ¯æž¶æž„](./model-architecture.md)
- [æ™ºèƒ½ä½“å¼€å‘æŒ‡å—](./getting-started.md)

---

**æœ€åŽæ›´æ–°æ—¶é—´**ï¼š2025-10-27

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0.0

å¦‚æœ‰ä»»ä½•ç–‘é—®æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·è”ç³»ï¼š
- ðŸ“§ é‚®ç®±ï¼šsupport@coze-plus.cn
- ðŸ’¬ äº¤æµç¾¤ï¼šå‚è§[é¡¹ç›®æ¦‚è¿°](./overview.md)
